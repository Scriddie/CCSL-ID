{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we analyse a sample of PBMCs. Here, we cover normalization, batch effect correction, selection of highly variable genes, computing cell cycle scores, conduct an initial clustering and visualisation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "369zExuTx_6g"
   },
   "source": [
    "\n",
    "Install all packages for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjjZ3KNDyDjd",
    "outputId": "3777f678-a170-41dd-fd92-28fbd464d9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scanpy==1.6.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/75/677a6c4e78e8e3ff9eedef49b7b1dd4ab1cfd442ecf3131be329ad374186/scanpy-1.6.1-py3-none-any.whl (10.2MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2MB 4.4MB/s \n",
      "\u001b[?25hCollecting umap-learn==0.4.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/21/e1eb2eb1c624a84f4a23237adb974e94ff7371ee8c178d246194af83fb80/umap-learn-0.4.6.tar.gz (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
      "\u001b[?25hCollecting anndata==0.7.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/b1/743cc79f89d9db6dccbfb7e6000795acb218a6c6320b7a2337cad99bd047/anndata-0.7.5-py3-none-any.whl (119kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 49.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
      "Collecting scrublet\n",
      "  Downloading https://files.pythonhosted.org/packages/21/74/82308f7bdcbda730b772a6d1afb6f55b9706601032126c4359afb3fb8986/scrublet-0.2.3-py3-none-any.whl\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
      "Collecting python-igraph==0.8.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/e6/bbabc4a420a426cc062ce007f27e786972e2964790a097c94bbb8e36788f/python_igraph-0.8.3-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 39.8MB/s \n",
      "\u001b[?25hCollecting louvain==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/5e/68f58d78088cab42dfcaa45c57ad691c025f9b246dda1d76d86a741f12ed/louvain-0.7.0-cp37-cp37m-manylinux2010_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 49.5MB/s \n",
      "\u001b[?25hCollecting leidenalg==0.8.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/68/3f7c56da3e7ac576e5e090f2a7e8637f96e4a790688dbee63b938530ef15/leidenalg-0.8.3-cp37-cp37m-manylinux2010_x86_64.whl (2.4MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4MB 46.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (20.9)\n",
      "Requirement already satisfied: patsy in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (0.5.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (4.41.1)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (5.5.0)\n",
      "Collecting sinfo\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/4c/aef8456284f1a1c3645b938d9ca72388c9c4878e6e67b8a349c7d22fac78/sinfo-0.3.1.tar.gz\n",
      "Collecting legacy-api-wrap\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/68/da997bc56bb69dcdcee4054f0bc42266909307b905389fbc54c9158f42da/legacy_api_wrap-1.2-py3-none-any.whl\n",
      "Requirement already satisfied: importlib-metadata>=0.7; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (3.4.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (1.0.1)\n",
      "Collecting setuptools-scm\n",
      "  Downloading https://files.pythonhosted.org/packages/db/6e/2815f7c8561b088ccedc128681e64daac3d6b2e81a9918b007e244dad8b1/setuptools_scm-5.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (3.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (0.22.2.post1)\n",
      "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (2.5)\n",
      "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (2.10.0)\n",
      "Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (0.10.2)\n",
      "Requirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.7/dist-packages (from scanpy==1.6.1) (0.51.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from scrublet) (0.16.2)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from scrublet) (0.29.21)\n",
      "Collecting annoy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/5b/1c22129f608b3f438713b91cd880dc681d747a860afe3e8e0af86e921942/annoy-1.17.0.tar.gz (646kB)\n",
      "\u001b[K     |████████████████████████████████| 655kB 44.3MB/s \n",
      "\u001b[?25hCollecting texttable>=1.6.2\n",
      "  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy->scanpy==1.6.1) (1.15.0)\n",
      "Collecting stdlib_list\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/b1/52f59dcf31ead2f0ceff8976288449608d912972b911f55dff712cef5719/stdlib_list-0.8.0-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 8.5MB/s \n",
      "\u001b[?25hCollecting get-version>=2.0.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/48/7610e884e62fff2183e7bc8592397c39a020267fb5147905fcd3f9cc820c/get_version-2.1-py3-none-any.whl (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from legacy-api-wrap->scanpy==1.6.1) (53.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.7; python_version < \"3.8\"->scanpy==1.6.1) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.7; python_version < \"3.8\"->scanpy==1.6.1) (3.7.4.3)\n",
      "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from tables->scanpy==1.6.1) (2.7.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.3->scanpy==1.6.1) (4.4.2)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.41.0->scanpy==1.6.1) (0.34.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->scrublet) (7.0.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->scrublet) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->scrublet) (2.4.1)\n",
      "Building wheels for collected packages: umap-learn, sinfo, annoy\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.4.6-cp37-none-any.whl size=67950 sha256=73d5cb1d3c6d934d02650d176b11047ea7b19bdb89855adbfc18070a7ff26e46\n",
      "  Stored in directory: /root/.cache/pip/wheels/7d/1d/03/34aade9a9b97acddb8e93654eb856dadbf0964406eef8b96e2\n",
      "  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sinfo: filename=sinfo-0.3.1-cp37-none-any.whl size=7012 sha256=bb127fa685485f839524349037891d37cc1fef1249ba1d798b14834188c16250\n",
      "  Stored in directory: /root/.cache/pip/wheels/11/f0/23/347d6d8e59787c2bc272162d18223dc3b45bd6dc40aceee6af\n",
      "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for annoy: filename=annoy-1.17.0-cp37-cp37m-linux_x86_64.whl size=391565 sha256=c58dc596624d8b8e3cef82a38dd91e8a414930604c7f25af6ed9f921ccfa180b\n",
      "  Stored in directory: /root/.cache/pip/wheels/3a/c5/59/cce7e67b52c8e987389e53f917b6bb2a9d904a03246fadcb1e\n",
      "Successfully built umap-learn sinfo annoy\n",
      "Installing collected packages: stdlib-list, sinfo, anndata, get-version, legacy-api-wrap, setuptools-scm, umap-learn, scanpy, annoy, scrublet, texttable, python-igraph, louvain, leidenalg\n",
      "  Found existing installation: umap-learn 0.5.1\n",
      "    Uninstalling umap-learn-0.5.1:\n",
      "      Successfully uninstalled umap-learn-0.5.1\n",
      "Successfully installed anndata-0.7.5 annoy-1.17.0 get-version-2.1 legacy-api-wrap-1.2 leidenalg-0.8.3 louvain-0.7.0 python-igraph-0.8.3 scanpy-1.6.1 scrublet-0.2.3 setuptools-scm-5.0.1 sinfo-0.3.1 stdlib-list-0.8.0 texttable-1.6.3 umap-learn-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install scanpy==1.6.1 umap-learn==0.4.6 anndata==0.7.5 numpy==1.19.5 scipy==1.4.1 pandas matplotlib scrublet seaborn python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "konUvxFoyPC3"
   },
   "source": [
    "Load all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TiqLggKsx6jY"
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ann\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import colors\n",
    "\n",
    "import os \n",
    "#doublet detection\n",
    "import scrublet as scr\n",
    "\n",
    "\n",
    "#pretty plotting\n",
    "import seaborn as sb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPXTUvufx6jc",
    "outputId": "21748c80-c050-4bbe-8707-ed7770f7a2b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.6.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.4.1 pandas==1.1.5 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize']=(8,8) #rescale figures\n",
    "sc.settings.verbosity = 3\n",
    "#sc.set_figure_params(dpi=200, dpi_save=300)\n",
    "sc.logging.print_header()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0LMHYK5x6jf"
   },
   "source": [
    "Of note, this notebook was created as part of a workshop, so we use extra large legend texts in all seaborn plots. You can set the context as well to 'talk' or 'paper'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ObAcocr1x6jg"
   },
   "outputs": [],
   "source": [
    "sb.set_context(context='poster')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4YQP5Bxx6jl"
   },
   "source": [
    "# Set project file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w4JehCYycIt"
   },
   "source": [
    "Let us set up the connection with Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRY5suT9ybQz",
    "outputId": "3be5fdd1-e61b-4ef5-d9a1-40eee7e39ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcU2nPwOx6jl"
   },
   "source": [
    "We set up the file paths to the respective directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NEvvWdQhx6jl"
   },
   "outputs": [],
   "source": [
    "file_path = '/content/drive/My Drive/' #this is the file path to your google drive (main directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YW955dVHOGb-"
   },
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axR6OBhRx6jo"
   },
   "source": [
    "File path to the raw data. They are usually stored at a different location than the rest of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Nhja3qzVx6jp"
   },
   "outputs": [],
   "source": [
    "file_path_raw = file_path + '3k_PBMC/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU3JmkQlx6js"
   },
   "source": [
    "The data directory contains all processed data and `anndata` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Kpv68PxYx6jt"
   },
   "outputs": [],
   "source": [
    "data_dir = file_path + 'PBMC_Colabs/data/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIyfTE6mx6jx"
   },
   "source": [
    "The tables directory contains all tabular data output, e.g. in `.csv` or `.xls` file format. That applies to differential expression test results or overview tables such as the number of cells per cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RbT94tWAx6jy"
   },
   "outputs": [],
   "source": [
    "table_dir = file_path + 'PBMC_Colabs/tables/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZdFb4bsx6j0"
   },
   "source": [
    "The default figure path is a POSIX path calles 'figures'. If you don't change the default figure directory, scanpy creates a subdirectory where this notebook is located.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "x0PSnfOnx6j1"
   },
   "outputs": [],
   "source": [
    "sc.settings.figdir = file_path + 'PBMC_Colabs/figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ymh8mNlRx6j3"
   },
   "source": [
    "**Comment:** When you repeat certain analyses, it might be helpful to set a `date` variable and add it to every figure and table (see `datetime` Python package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.date.today().strftime('%y%m%d') #creates a YYMMDD string of today's date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The post-QC dataset, which consists of 3k PBMCs (Human) provided by 10X Genomics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(data_dir + 'data_postQC.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Batch effect correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A82ZGkhGx6k5"
   },
   "source": [
    "So far, our dataset is a count matrix. Here, every count corresponds to an mRNA molecule captured in the scRNA-seq experiment. As not all mRNA molecules in a cell are captured, there is a variability in the total number of counts detected between cells that results from both the number of molecules that were in the cells, and the sampling. As we cannot assume that all cells contain an equal number of molecules (cell sizes can differ substantially), we have to estimate the number of molecules that were initially in the cells. In fact, we don't estimate the exact number of molecules, but instead estimate cell-specific factors that should be proportional to the true number of molecules. These are called size factors. Normalized expression values are calculated by dividing the measured counts by the size factor for the cell.\n",
    "\n",
    "Several methods for normalization for scRNA-seq data have been proposed. Ideally, we want to apply the `scran` library size normalization followed by log-transformation. However, `scran` is again an R package, and we use the simpler normalisation to logCPM, `i.e.` we divide by the library size followed by the log-transformation. In addition, we save the count matrix to `layers` as 'counts'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NESopdYgx6k6"
   },
   "source": [
    "**Comment:** For `scran`, we have not (comprehensively) tested whether normalisation per sample or all samples jointly gives more accurate results. When we normalised per sample, observed many more differentially expressed genes across conditions (in the range of thousands). We think that normalisation per sample preserves a systematic bias while joint normalisation removes batch effects within the same cluster partially, if a cluster contains cell from several batches. No such effect of the normalisation can be observed when samples do not overlap at all. For the time being, we perform joint normalisation of all samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "pz_me6j0x6k7"
   },
   "outputs": [],
   "source": [
    "adata.layers['counts'] = adata.X.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWiOWVc22AnR"
   },
   "source": [
    "We use the logCPM normalisation, with minor adaptations: After normalization, each observation (cell) has a total count equal to the median of total counts for observations (cells) before normalization. Then, we scale all values with log(x+1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP15EF0d12bx",
    "outputId": "1d2bcbbf-3a10-4e76-c9ae-f1f0e62d9d2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing counts per cell\n",
      "    finished (0:00:00)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks:** Plot library size vs number of expressed genes.\n",
    "\n",
    "**Questions:** How does the library size relate to number of expressed genes? Can we suspect cell type specific differences in the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch correction - general remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of a single batch, thus, batch effect correction is not an issue here. If you handle several batches, you may observe differences across samples, for instance, in the library size per dataset. Such differences may contribute to the batch effect. [Büttner et al., Nat Meth (2019)](https://www.nature.com/articles/s41592-018-0254-1) compared the performance of several batch correction methods. For low-to-medium complexity datasets, ComBat performed best among the tested tools. ComBat is also available in `scanpy` (see `sc.pp.combat`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For high complexity data, especially when you encounter changes in cell type composition, consider to use a data integration method of your choice. We distinguish three different types, *i.e.* if the methods create a corrected data matrix (in feature space), an embedding or a knn-graph. Examples are:\n",
    "1. feature space: MNN (`scanpy.external.pp.mnn_correct`), scanorama (integrates with scanpy), Seurat v3 (R based)\n",
    "2. embedding: scVI (Python based), Harmony (R based), scanorama\n",
    "3. knn-graph: conos (R based), BBKNN (`scanpy.external.pp.bbknn`)\n",
    "\n",
    "Several benchmarking studies aimed to determine best performing methods. In simple cases, Seurat v3 and Harmony performed best [Tran et al., Genome Biology (2020)](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1850-9) and [Chazarra-Gil et al., biorxiv (2020)](https://www.biorxiv.org/content/10.1101/2020.05.22.111211v2). More complex scenarios have been benchmarked in [Luecken et al., biorxiv (2020)](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), where BBKNN, Scanorama, and scVI performed well. Furthermore, Scanorama had high scores in the preservation of biological signals, while BBKNN tended to overcorrect. Moreover, Luecken et al. tested different pre-processing schemes. In general, **selecting highly variable genes prior to batch correction improved the batch effect correction result**. We continue with the selection of highly variable genes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (Highly variable genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract highly variable genes (HVGs) to further reduce the dimensionality of the dataset and include only the most informative genes. Genes that vary substantially across the dataset are informative of the underlying biological variation in the data. As we only want to capture biological variation in these genes, we select highly variable genes after normalization and batch correction. HVGs are used for clustering, trajectory inference, and dimensionality reduction/visualization, while the full data set is used for computing marker genes, differential testing, cell cycle scoring, and visualizing expression values on the data.\n",
    "\n",
    "Here we use a standard technique for the extraction of highly variable genes from the 10X genomics preprocessing software *CellRanger*. Typically between 1000 and 5000 genes are selected. Here, we extract the top 4000 most variable genes for further processing. If particular genes of importance are known, one could assess how many highly variable genes are necessary to include all, or the majority, of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute highly variable genes and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000)\n",
    "print('\\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize']=(10,5)\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show how the data was normalized to select highly variable genes irrespective of the mean expression of the genes. This is achieved by using the index of dispersion which divides by mean expression, and subsequently binning the data by mean expression and selecting the most variable genes within each bin.\n",
    "\n",
    "Highly variable gene information is stored automatically in the `adata.var['highly_variable']` field. The dataset now contains:\n",
    "\n",
    "* count data as layer 'counts' in adata\n",
    "* log-scran normalized data in adata.X\n",
    "* highly variable gene annotations in `adata.var['highly_variable']`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell cycle scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Known sources of technical variation in the data have been investigated and corrected for (e.g. batch, count depth). A known source of biological variation that can explain the data is the cell cycle. Here, gene lists from [Macosko et al., Cell 161 (2015)](https://www.sciencedirect.com/science/article/pii/S0092867415005498) is used to score the cell cycle effect in the data and classify cells by cell cycle phase. The file can be found on the [scIB github repository](https://github.com/theislab/scib/tree/master/scIB/resources/).\n",
    "\n",
    "Please note, that the gene list was generated for human HeLa cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_genes_file = data_dir + 's_genes_tirosh_hm.txt'\n",
    "g2m_genes_file = data_dir + 'g2m_genes_tirosh_hm.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_genes = pd.read_table(s_genes_file, header = None).values.flatten()\n",
    "g2m_genes = pd.read_table(g2m_genes_file, header = None).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_genes_hvg = adata.var_names[np.in1d(adata.var_names, s_genes)]\n",
    "g2m_genes_hvg = adata.var_names[np.in1d(adata.var_names, g2m_genes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cell cycle score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_hvg, g2m_genes=g2m_genes_hvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(s_genes_hvg))\n",
    "print(len(g2m_genes_hvg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['phase'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENT:** End of third session. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## low dimensional embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing scRNA-seq data is the process of projecting a high-dimensional matrix of cells and genes into a few coordinates such that every cell is meaningfully represented in a two-dimensional graph. However, the visualization of scRNA-seq data is an active area of research and each method defines 'meaningful' in its own way. \n",
    "\n",
    "Overall t-SNE visualizations have been very popular in the community, however the recent UMAP algorithm has been shown to better represent the topology of the data.\n",
    "\n",
    "We will look at several visualizations to decide which visualization best represents the aspect of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the following embeddings: PCA, t-SNE, UMAP, diffusion map and force-directed graph. Please compute PCA first and compute nearest neighbors next. All other embeddings rely on this information. Visualize the embeddings and color by the total number of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the number of informative principal components, let us review the variance contribution of each component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the elbow method, we select the first **XX** PCs as informative.\n",
    "\n",
    "It must be noted that the elbow method is not a strict scientific criterion to select the correct number of PCs. For instance, the variance of the gene expression from rare cell types might only be covered by the latter PCs. Therefore, consider to try out different numbers of PCs and examine the differences in the resulting low-dimensional embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Decide on the number of informative principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata, n_comps= ,#number of informative components  \n",
    "          use_highly_variable=True, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.tsne(adata) #Note n_jobs works for MulticoreTSNE, but not regular implementation)\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.diffmap(adata)\n",
    "sc.tl.draw_graph(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize']=(20,10)\n",
    "fig_ind=np.arange(231, 237)\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.6)\n",
    "\n",
    "p10 = sc.pl.pca_scatter(adata, color='n_counts', ax=fig.add_subplot(fig_ind[0]), show=False)\n",
    "p11 = sc.pl.tsne(adata, color='n_counts', ax=fig.add_subplot(fig_ind[1]), show=False)\n",
    "p12 = sc.pl.umap(adata, color='n_counts', ax=fig.add_subplot(fig_ind[2]), show=False)\n",
    "p13 = sc.pl.diffmap(adata, color='n_counts', components=['1,2'], ax=fig.add_subplot(fig_ind[3]),show=False)\n",
    "p14 = sc.pl.diffmap(adata, color='n_counts', components=['1,3'], ax=fig.add_subplot(fig_ind[4]), show=False)\n",
    "p15 = sc.pl.draw_graph(adata, color='n_counts', ax=fig.add_subplot(fig_ind[5]), show=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA**:\n",
    "\n",
    "* Unsurprisingly, the first principle component captures variation in count depth between cells, and is thus only marginally informative\n",
    "* The plot shows a weak clustering of the data in two dimensions\n",
    "\n",
    "**t-SNE**:\n",
    "\n",
    "* Shows several distinct clusters with clear subcluster structure\n",
    "* Connections between clusters are difficult to interpret visually\n",
    "\n",
    "**UMAP**:\n",
    "\n",
    "* Data points are spread out on the plot showing several clusters\n",
    "* Connections between clusters also not visible (and not expected for PBMC data)\n",
    "\n",
    "**Diffusion Maps**:\n",
    "\n",
    "* Shows regions of higher density and a few disconnected cells in between\n",
    "* Trajectories not visible (and not expected for PBMC data)\n",
    "* Each diffusion component extracts heterogeneity in a different part of the data\n",
    "\n",
    "**Graph**:\n",
    "\n",
    "* Shows several clusters with substructure\n",
    "* Lack of trajectories as expected\n",
    "\n",
    "The strengths and weaknesses of the visualizations can readily be identified in the above plots. While t-SNE exaggerates differences, diffusion maps exaggerate transitions. Overall UMAP and force-directed graph drawings show the best compromise of the two aspects, however UMAP is much faster to compute. UMAP has furthermore been shown to more accurately display the structure in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us compute an embedding density. We use the UMAP representation as basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.embedding_density(adata, basis='umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize']=(7,7)\n",
    "sc.pl.embedding_density(adata, basis='umap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise cell cycle score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Check whether MKI67 is present in the dataset and visualise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint 'MKI67' has to be in the adata.var_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize']=(5,5)\n",
    "#plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Plot a low-dimensional embedding and show the cell cycle scores and the predicted phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize']=(5,5)\n",
    "#plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, all cells are assigned to the same proliferative cell cycle phase (G2M), but inspecting the interface marker MKI67 shows little evidence for proliferation. If the phase score looks suspicious, one has to adjust the threshold for assigning a certain phase. By default, a cell is G1, if both S and G2M score are negative. Otherwise, a cell is assigned to the phase where it has the highest score. Potentially, we would need to adapt the cutoffs of the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point of the analysis, we have reached an important milestone as we finished the pre-processing and enter the downstream analysis part. **Ideally, we don't have to revisit this part again.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(data_dir + 'data_processed.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** End of third session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise gene expression\n",
    "\n",
    "In this session, we focus on the various plotting functions in `scanpy` to visualise gene expression patterns per cell and for groups of cells. On the one hand, using various ways of visualising data helps to find patterns and identify cell types. On the other hand, we aim to show how to prettify plots in `scanpy`. \n",
    "\n",
    "We will look at visualising gene expression:\n",
    "* on low dimensional embedding plots\n",
    "* as heatmap\n",
    "* as tracksplot\n",
    "* as matrixplot\n",
    "* as (stacked) violin plot\n",
    "* as dotplot\n",
    "\n",
    "\n",
    "Please note that we leave the \"stringent\" data analysis workflow. When you start working with `scanpy` in your own analysis projects, you might single out a few plotting functions, which you find the most useful to quickly explore the data, and only reconsider other means to visualise data only upon finalising a project. \n",
    "\n",
    "In order to display groups of cells, we will use a clustering approach called \"leiden clustering\", which will be explained in detail on day 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualise gene expression on low dimensional embeddings. We use some marker genes for PBMCs (e.g. CD79A, CD3D, MS4A1, FCER1A).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 3,3\n",
    "sc.pl.umap(adata, color=['CD79A', 'MS4A1', 'CD3D', 'FCER1A'], \n",
    "           ncols=2, #number of columns to use \n",
    "           hspace=0.5, #space between 2 rows\n",
    "           wspace=0.3, #space between 2 columns\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us prettify the plots: The maximum value plotted can be adjusted using `vmax` (similarly vmin can be used for the minimum value). In this case we use `p99`, which means to use as max value the 99 percentile (less biased by outliers). The max value can be a number or a list of numbers if the `vmax` wants to be set for multiple plots individually.\n",
    "\n",
    "Also, we are using `frameon=False` to remove the boxes around the plots and `s=50` to set the dot size. Lastly, we change the color map to a Red scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 3,3\n",
    "sc.pl.umap(adata, color=['CD79A', 'MS4A1', 'CD3D', 'FCER1A'], \n",
    "           hspace=0.5, #space between 2 rows\n",
    "           wspace=0.3, #space between 2 columns\n",
    "           s=50, #dot size\n",
    "           frameon=False, ncols=2, vmax='p99',\n",
    "           color_map='Reds'\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us scale the data and save it as `layer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and store results in layer\n",
    "adata.layers['scaled'] = sc.pp.scale(adata, copy=True).X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute low resolution clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, key_added='clusters', resolution=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise clustering. The functions for scatterplots have many options that allow fine tuning of the images. For example, we can look at the clustering as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 5, 5\n",
    "sc.pl.umap(adata, color='clusters', #plot categorical values\n",
    "           add_outline=True, #black outline on all cells\n",
    "           legend_loc='on data', #plot cluster ID on data\n",
    "           legend_fontsize=12, \n",
    "           legend_fontoutline=2,\n",
    "           frameon=False,\n",
    "           title='clustering of cells', \n",
    "           palette='Set3' #use a colorbrewer scheme for categorical data\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full set of options can be found in the documentation of the plotting functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a violin plot with and without internal dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(adata, keys=['CD3D', 'MS4A1', 'FCER1A'],\n",
    "              groupby='clusters', \n",
    "              dendrogram=True, figsize=(5,4))\n",
    "sc.pl.violin(adata, keys=['CD3D', 'MS4A1', 'FCER1A'],\n",
    "              groupby='clusters',  stripplot=False,\n",
    "              dendrogram=True, figsize=(5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.heatmap(adata, var_names=['CD3D', 'MS4A1', 'FCER1A'], \n",
    "              figsize=(7,5), #set figure shape\n",
    "              groupby='clusters', cmap='viridis', dendrogram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `swap_axes=True` command to create a horizontal heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.heatmap(adata, var_names=['CD3D', 'MS4A1', 'FCER1A'], \n",
    "              groupby='clusters', \n",
    "              cmap='viridis', #color map\n",
    "              dendrogram=True, swap_axes=True, figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the scaled version of the data and use a diverging color map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.heatmap(adata, var_names=['CD3D', 'MS4A1', 'FCER1A'], layer='scaled',\n",
    "              groupby='clusters', \n",
    "              vmin=-2, vmax=2, #fix minimum and maximum\n",
    "              cmap='RdBu_r',  #color map\n",
    "              dendrogram=True, swap_axes=True, figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a tracksplot instead of a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.tracksplot(adata, var_names=['CD3D', 'MS4A1', 'FCER1A'],\n",
    "              groupby='clusters', \n",
    "              dendrogram=True, swap_axes=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dotplot, a matrixplot and a stacked violin plot by replacing the corresponding keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, var_names=['CD3D', 'MS4A1', 'FCER1A'],\n",
    "              groupby='clusters', \n",
    "              dendrogram=True, figsize=(5,4))\n",
    "\n",
    "sc.pl.stacked_violin(adata, var_names=['CD3D', 'MS4A1', 'FCER1A'],\n",
    "              groupby='clusters', \n",
    "              dendrogram=True, figsize=(5,4))\n",
    "\n",
    "sc.pl.matrixplot(adata, var_names=['CD3D', 'MS4A1', 'FCER1A'],\n",
    "              groupby='clusters', \n",
    "              dendrogram=True, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced plotting: Add cluster size as barchart to the top of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = sc.pl.stacked_violin(adata,var_names=['CD3D', 'MS4A1', 'FCER1A'], swap_axes=True,\n",
    "              groupby='clusters', return_fig=True)\n",
    "vp.add_totals().style(ylim=(0,5)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More inspiration can be found in the [scanpy plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html) and the [scanpy plotting documentation](https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks:** Choose one of the plots and customize it to your liking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "* Take your favourite embedding and display all genes of interest on the same color scale (0-1). \n",
    "* Choose your own color scale, please get inspired from the [list of colors](https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html)\n",
    "* Plot only two of the clusters.\n",
    "* Remove the dendrogram.\n",
    "* Change the figure size and shape.\n",
    "* Save the plot to file (formats: PNG, PDF) - check, if the margins are correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a list of marker genes from literature for the subpopulations of PBMCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes = ['IL7R', 'CD79A', 'MS4A1', 'CD8A', 'CD8B', 'LYZ', 'CD14',\n",
    "                'LGALS3', 'S100A8', 'GNLY', 'NKG7', 'KLRB1',\n",
    "                'FCGR3A', 'MS4A7', 'FCER1A', 'CST3', 'PPBP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** End of fourth session and day 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(data_dir + 'data_processed-vis.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
